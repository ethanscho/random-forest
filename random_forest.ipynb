{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "from random import seed\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 0, 'R': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    " \n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup\n",
    "\n",
    "filename = 'sonar.all-data.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# convert string attributes to integers\n",
    "for i in range(0, len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "    \n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle, split training, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 42\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(dataset)\n",
    "\n",
    "n_training = int(len(dataset) * 0.8)\n",
    "training_set = dataset[:n_training]\n",
    "test_set = dataset[n_training:]\n",
    "\n",
    "print (len(training_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_set)[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(index, value, dataset):\n",
    "\tleft, right = [], []\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = int(sqrt(len(training_set[1]) - 1))\n",
    "MAX_DEPTH = 15\n",
    "MIN_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node contains the information of feature index, criterion value, gini score and lastly split groups (left and right) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_node(training_set):\n",
    "    class_values = [0.0, 1.0]\n",
    "    \n",
    "    selected_features = np.arange(N_FEATURES)\n",
    "    np.random.shuffle(selected_features)\n",
    "    \n",
    "    selected_features = selected_features[:N_FEATURES]\n",
    "    \n",
    "    trained_feature_index = 1000\n",
    "    trained_value = 1000.0\n",
    "    trained_gini_score = 1000.0\n",
    "    trained_group = None\n",
    "    \n",
    "    for feature_index in selected_features:\n",
    "        for row in training_set:\n",
    "            value = row[feature_index]\n",
    "            group = split(feature_index, value, training_set)\n",
    "            gini = gini_index(group, class_values)\n",
    "            \n",
    "            if gini < trained_gini_score:\n",
    "                trained_feature_index = feature_index\n",
    "                trained_value = value\n",
    "                trained_gini_score = gini\n",
    "                trained_group = group\n",
    "                \n",
    "    return {'trained_feature_index':trained_feature_index, 'trained_value':trained_value, 'trained_gini_score':trained_gini_score, 'trained_group':trained_group}           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_value(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "def expand_branch(node, depth):\n",
    "    left, right = node['trained_group']\n",
    "\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        value = terminal_value(left + right)\n",
    "        node['left'] = value\n",
    "        node['right'] = value\n",
    "        return\n",
    "\n",
    "    if depth >= MAX_DEPTH:\n",
    "        node['left'], node['right'] = terminal_value(left), terminal_value(right)\n",
    "        return\n",
    "\n",
    "    if len(left) <= MIN_SIZE:\n",
    "        node['left'] = terminal_value(left)\n",
    "    else:\n",
    "        node['left'] = make_node(left)\n",
    "        expand_branch(node['left'], depth + 1)\n",
    "\n",
    "    if len(right) <= MIN_SIZE:\n",
    "        node['right'] = terminal_value(right)\n",
    "    else:\n",
    "        node['right'] = make_node(right)\n",
    "        expand_branch(node['right'], depth + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(training_set):\n",
    "    root = make_node(training_set)\n",
    "    expand_branch(root, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "NUM_TREES = 10\n",
    "trees = []\n",
    "for i in range(NUM_TREES):\n",
    "    trees.append(make_tree(training_set))\n",
    "\n",
    "print(len(trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging result from each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "\tif row[node['trained_feature_index']] < node['trained_value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for row in test_set:\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    #print(predictions)\n",
    "    bagged_result = max(set(predictions), key=predictions.count)\n",
    "    #print(bagged_result)\n",
    "    result.append(bagged_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = np.array(result).astype(float)\n",
    "\n",
    "actual_classes = np.array(test_set)[:,-1]\n",
    "\n",
    "final_result = actual_classes == predicted_classes\n",
    "\n",
    "print (sum(final_result) / len(final_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
